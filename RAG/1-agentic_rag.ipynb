{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec00a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"gemma2-9b-it\")\n",
    "llm\n",
    "gamini_key=os.getenv(\"GAMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ccf2b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bee42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=[\n",
    "    \"https://langchain-ai.github.io/langgraph/concepts/why-langgraph/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/get-started/2-add-tools/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/get-started/4-human-in-the-loop/\"\n",
    "]\n",
    "\n",
    "docs=[WebBaseLoader(url).load() for url in url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da956aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/why-langgraph/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\nLangGraph Platform docs have moved! Find the LangGraph Platform docs at the new LangChain Docs site.\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Overview\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Get started\\n          \\n\\n\\n\\n\\n\\n    Quickstarts\\n    \\n  \\n\\n\\n\\n\\n\\n            Quickstarts\\n          \\n\\n\\n\\n\\n    Start with a prebuilt agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Build a custom workflow\\n    \\n  \\n\\n\\n\\n\\n\\n            Build a custom workflow\\n          \\n\\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Learn LangGraph basics\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    1. Build a basic chatbot\\n    \\n  \\n\\n\\n\\n\\n\\n    2. Add tools\\n    \\n  \\n\\n\\n\\n\\n\\n    3. Add memory\\n    \\n  \\n\\n\\n\\n\\n\\n    4. Add human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    5. Customize state\\n    \\n  \\n\\n\\n\\n\\n\\n    6. Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Run a local server\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    General concepts\\n    \\n  \\n\\n\\n\\n\\n\\n            General concepts\\n          \\n\\n\\n\\n\\n    Workflows & agents\\n    \\n  \\n\\n\\n\\n\\n\\n    Agent architectures\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Learn LangGraph basics\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOverview¶\\nLangGraph is built for developers who want to build powerful, adaptable AI agents. Developers choose LangGraph for:\\n\\nReliability and controllability. Steer agent actions with moderation checks and human-in-the-loop approvals. LangGraph persists context for long-running workflows, keeping your agents on course.\\nLow-level and extensible. Build custom agents with fully descriptive, low-level primitives free from rigid abstractions that limit customization. Design scalable multi-agent systems, with each agent serving a specific role tailored to your use case.\\nFirst-class streaming support. With token-by-token streaming and streaming of intermediate steps, LangGraph gives users clear visibility into agent reasoning and actions as they unfold in real time.\\n\\nLearn LangGraph basics¶\\nTo get acquainted with LangGraph's key concepts and features, complete the following LangGraph basics tutorials series:\\n\\nBuild a basic chatbot\\nAdd tools\\nAdd memory\\nAdd human-in-the-loop controls\\nCustomize state\\nTime travel\\n\\nIn completing this series of tutorials, you will build a support chatbot in LangGraph that can:\\n\\n✅ Answer common questions by searching the web\\n✅ Maintain conversation state across calls  \\n✅ Route complex queries to a human for review  \\n✅ Use custom state to control its behavior  \\n✅ Rewind and explore alternative conversation paths  \\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Start with a prebuilt agent\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                1. Build a basic chatbot\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")],\n",
       " [Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/get-started/2-add-tools/', 'title': '2. Add tools', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2. Add tools\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\nLangGraph Platform docs have moved! Find the LangGraph Platform docs at the new LangChain Docs site.\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              2. Add tools\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Get started\\n          \\n\\n\\n\\n\\n\\n    Quickstarts\\n    \\n  \\n\\n\\n\\n\\n\\n            Quickstarts\\n          \\n\\n\\n\\n\\n    Start with a prebuilt agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Build a custom workflow\\n    \\n  \\n\\n\\n\\n\\n\\n            Build a custom workflow\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    1. Build a basic chatbot\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    2. Add tools\\n    \\n  \\n\\n\\n\\n\\n    2. Add tools\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Prerequisites\\n    \\n\\n\\n\\n\\n\\n      1. Install the search engine\\n    \\n\\n\\n\\n\\n\\n      2. Configure your environment\\n    \\n\\n\\n\\n\\n\\n      3. Define the tool\\n    \\n\\n\\n\\n\\n\\n      4. Define the graph\\n    \\n\\n\\n\\n\\n\\n      5. Create a function to run the tools\\n    \\n\\n\\n\\n\\n\\n      6. Define the conditional_edges\\n    \\n\\n\\n\\n\\n\\n      7. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      8. Ask the bot questions\\n    \\n\\n\\n\\n\\n\\n      9. Use prebuilts\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    3. Add memory\\n    \\n  \\n\\n\\n\\n\\n\\n    4. Add human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    5. Customize state\\n    \\n  \\n\\n\\n\\n\\n\\n    6. Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Run a local server\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    General concepts\\n    \\n  \\n\\n\\n\\n\\n\\n            General concepts\\n          \\n\\n\\n\\n\\n    Workflows & agents\\n    \\n  \\n\\n\\n\\n\\n\\n    Agent architectures\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Prerequisites\\n    \\n\\n\\n\\n\\n\\n      1. Install the search engine\\n    \\n\\n\\n\\n\\n\\n      2. Configure your environment\\n    \\n\\n\\n\\n\\n\\n      3. Define the tool\\n    \\n\\n\\n\\n\\n\\n      4. Define the graph\\n    \\n\\n\\n\\n\\n\\n      5. Create a function to run the tools\\n    \\n\\n\\n\\n\\n\\n      6. Define the conditional_edges\\n    \\n\\n\\n\\n\\n\\n      7. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      8. Ask the bot questions\\n    \\n\\n\\n\\n\\n\\n      9. Use prebuilts\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd tools¶\\nTo handle queries that your chatbot can\\'t answer \"from memory\", integrate a web search tool. The chatbot can use this tool to find relevant information and provide better responses.\\n\\nNote\\nThis tutorial builds on Build a basic chatbot.\\n\\nPrerequisites¶\\nBefore you start this tutorial, ensure you have the following:\\n\\nAn API key for the Tavily Search Engine.\\n\\n1. Install the search engine¶\\nInstall the requirements to use the Tavily Search Engine:\\npip install -U langchain-tavily\\n\\n2. Configure your environment¶\\nConfigure your environment with your search engine API key:\\nimport os\\n\\nos.environ[\"TAVILY_API_KEY\"] = \"tvly-...\"\\n\\n3. Define the tool¶\\nDefine the web search tool:\\nAPI Reference: TavilySearch\\nfrom langchain_tavily import TavilySearch\\n\\ntool = TavilySearch(max_results=2)\\ntools = [tool]\\ntool.invoke(\"What\\'s a \\'node\\' in LangGraph?\")\\n\\nThe results are page summaries our chat bot can use to answer questions:\\n{\\'query\\': \"What\\'s a \\'node\\' in LangGraph?\",\\n\\'follow_up_questions\\': None,\\n\\'answer\\': None,\\n\\'images\\': [],\\n\\'results\\': [{\\'title\\': \"Introduction to LangGraph: A Beginner\\'s Guide - Medium\",\\n\\'url\\': \\'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141\\',\\n\\'content\\': \\'Stateful Graph: LangGraph revolves around the concept of a stateful graph, where each node in the graph represents a step in your computation, and the graph maintains a state that is passed around and updated as the computation progresses. LangGraph supports conditional edges, allowing you to dynamically determine the next node to execute based on the current state of the graph. We define nodes for classifying the input, handling greetings, and handling search queries. def classify_input_node(state): LangGraph is a versatile tool for building complex, stateful applications with LLMs. By understanding its core concepts and working through simple examples, beginners can start to leverage its power for their projects. Remember to pay attention to state management, conditional edges, and ensuring there are no dead-end nodes in your graph.\\',\\n\\'score\\': 0.7065353,\\n\\'raw_content\\': None},\\n{\\'title\\': \\'LangGraph Tutorial: What Is LangGraph and How to Use It?\\',\\n\\'url\\': \\'https://www.datacamp.com/tutorial/langgraph-tutorial\\',\\n\\'content\\': \\'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.\\',\\n\\'score\\': 0.5008063,\\n\\'raw_content\\': None}],\\n\\'response_time\\': 1.38}\\n\\n4. Define the graph¶\\nFor the StateGraph you created in the first tutorial, add bind_tools on the LLM. This lets the LLM know the correct JSON format to use if it wants to use the search engine.\\nLet\\'s first select our LLM:\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n👉 Read the OpenAI integration docs\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n👉 Read the Anthropic integration docs\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n👉 Read the Azure integration docs\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n👉 Read the Google GenAI integration docs\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n👉 Read the AWS Bedrock integration docs\\n\\n\\n\\n\\nWe can now incorporate it into a StateGraph:\\nAPI Reference: StateGraph | START | END | add_messages\\nfrom typing import Annotated\\n\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.graph import StateGraph, START, END\\nfrom langgraph.graph.message import add_messages\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\ngraph_builder = StateGraph(State)\\n\\n# Modification: tell the LLM which tools it can call\\nllm_with_tools = llm.bind_tools(tools)\\n\\ndef chatbot(state: State):\\n    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\n5. Create a function to run the tools¶\\nNow, create a function to run the tools if they are called. Do this by adding the tools to a new node called BasicToolNode that checks the most recent message in the state and calls tools if the message contains tool_calls. It relies on the LLM\\'s tool_calling support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers.\\nAPI Reference: ToolMessage\\nimport json\\n\\nfrom langchain_core.messages import ToolMessage\\n\\n\\nclass BasicToolNode:\\n    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\\n\\n    def __init__(self, tools: list) -> None:\\n        self.tools_by_name = {tool.name: tool for tool in tools}\\n\\n    def __call__(self, inputs: dict):\\n        if messages := inputs.get(\"messages\", []):\\n            message = messages[-1]\\n        else:\\n            raise ValueError(\"No message found in input\")\\n        outputs = []\\n        for tool_call in message.tool_calls:\\n            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\\n                tool_call[\"args\"]\\n            )\\n            outputs.append(\\n                ToolMessage(\\n                    content=json.dumps(tool_result),\\n                    name=tool_call[\"name\"],\\n                    tool_call_id=tool_call[\"id\"],\\n                )\\n            )\\n        return {\"messages\": outputs}\\n\\n\\ntool_node = BasicToolNode(tools=[tool])\\ngraph_builder.add_node(\"tools\", tool_node)\\n\\n\\nNote\\nIf you do not want to build this yourself in the future, you can use LangGraph\\'s prebuilt ToolNode.\\n\\n6. Define the conditional_edges¶\\nWith the tool node added, now you can define the conditional_edges.\\nEdges route the control flow from one node to the next. Conditional edges start from a single node and usually contain \"if\" statements to route to different nodes depending on the current graph state. These functions receive the current graph state and return a string or list of strings indicating which node(s) to call next.\\nNext, define a router function called route_tools that checks for tool_calls in the chatbot\\'s output. Provide this function to the graph by calling add_conditional_edges, which tells the graph that whenever the chatbot node completes to check this function to see where to go next.\\nThe condition will route to tools if tool calls are present and END if not. Because the condition can return END, you do not need to explicitly set a finish_point this time.\\ndef route_tools(\\n    state: State,\\n):\\n    \"\"\"\\n    Use in the conditional_edge to route to the ToolNode if the last message\\n    has tool calls. Otherwise, route to the end.\\n    \"\"\"\\n    if isinstance(state, list):\\n        ai_message = state[-1]\\n    elif messages := state.get(\"messages\", []):\\n        ai_message = messages[-1]\\n    else:\\n        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\\n    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\\n        return \"tools\"\\n    return END\\n\\n\\n# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\\n# it is fine directly responding. This conditional routing defines the main agent loop.\\ngraph_builder.add_conditional_edges(\\n    \"chatbot\",\\n    route_tools,\\n    # The following dictionary lets you tell the graph to interpret the condition\\'s outputs as a specific node\\n    # It defaults to the identity function, but if you\\n    # want to use a node named something else apart from \"tools\",\\n    # You can update the value of the dictionary to something else\\n    # e.g., \"tools\": \"my_tools\"\\n    {\"tools\": \"tools\", END: END},\\n)\\n# Any time a tool is called, we return to the chatbot to decide the next step\\ngraph_builder.add_edge(\"tools\", \"chatbot\")\\ngraph_builder.add_edge(START, \"chatbot\")\\ngraph = graph_builder.compile()\\n\\n\\nNote\\nYou can replace this with the prebuilt tools_condition to be more concise.\\n\\n7. Visualize the graph (optional)¶\\nYou can visualize the graph using the get_graph method and one of the \"draw\" methods, like draw_ascii or draw_png. The draw methods each require additional dependencies.\\nfrom IPython.display import Image, display\\n\\ntry:\\n    display(Image(graph.get_graph().draw_mermaid_png()))\\nexcept Exception:\\n    # This requires some extra dependencies and is optional\\n    pass\\n\\n\\n8. Ask the bot questions¶\\nNow you can ask the chatbot questions outside its training data:\\ndef stream_graph_updates(user_input: str):\\n    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\\n        for value in event.values():\\n            print(\"Assistant:\", value[\"messages\"][-1].content)\\n\\nwhile True:\\n    try:\\n        user_input = input(\"User: \")\\n        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\\n            print(\"Goodbye!\")\\n            break\\n\\n        stream_graph_updates(user_input)\\n    except:\\n        # fallback if input() is not available\\n        user_input = \"What do you know about LangGraph?\"\\n        print(\"User: \" + user_input)\\n        stream_graph_updates(user_input)\\n        break\\n\\nAssistant: [{\\'text\\': \"To provide you with accurate and up-to-date information about LangGraph, I\\'ll need to search for the latest details. Let me do that for you.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01Q588CszHaSvvP2MxRq9zRD\\', \\'input\\': {\\'query\\': \\'LangGraph AI tool information\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\nAssistant: [{\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"LangGraph sets the foundation for how we can build and scale AI workloads \\\\u2014 from conversational agents, complex task automation, to custom LLM-backed experiences that \\'just work\\'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution ...\"}, {\"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"Overview. LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures ...\"}]\\nAssistant: Based on the search results, I can provide you with information about LangGraph:\\n\\n1. Purpose:\\n   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It\\'s particularly useful for creating agent and multi-agent workflows.\\n\\n2. Developer:\\n   LangGraph is developed by LangChain, a company known for its tools and frameworks in the AI and LLM space.\\n\\n3. Key Features:\\n   - Cycles: LangGraph allows the definition of flows that involve cycles, which is essential for most agentic architectures.\\n   - Controllability: It offers enhanced control over the application flow.\\n   - Persistence: The library provides ways to maintain state and persistence in LLM-based applications.\\n\\n4. Use Cases:\\n   LangGraph can be used for various applications, including:\\n   - Conversational agents\\n   - Complex task automation\\n   - Custom LLM-backed experiences\\n\\n5. Integration:\\n   LangGraph works in conjunction with LangSmith, another tool by LangChain, to provide an out-of-the-box solution for building complex, production-ready features with LLMs.\\n\\n6. Significance:\\n...\\n   LangGraph is noted to offer unique benefits compared to other LLM frameworks, particularly in its ability to handle cycles, provide controllability, and maintain persistence.\\n\\nLangGraph appears to be a significant tool in the evolving landscape of LLM-based application development, offering developers new ways to create more complex, stateful, and interactive AI systems.\\nGoodbye!\\n\\n9. Use prebuilts¶\\nFor ease of use, adjust your code to replace the following with LangGraph prebuilt components. These have built in functionality like parallel API execution.\\n\\nBasicToolNode is replaced with the prebuilt ToolNode\\nroute_tools is replaced with the prebuilt tools_condition\\n\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n👉 Read the OpenAI integration docs\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n👉 Read the Anthropic integration docs\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n👉 Read the Azure integration docs\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n👉 Read the Google GenAI integration docs\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n👉 Read the AWS Bedrock integration docs\\n\\n\\n\\n\\n\\nfrom typing import Annotated\\n\\nfrom langchain_tavily import TavilySearch\\nfrom langchain_core.messages import BaseMessage\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.graph import StateGraph, START, END\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.prebuilt import ToolNode, tools_condition\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\ngraph_builder = StateGraph(State)\\n\\ntool = TavilySearch(max_results=2)\\ntools = [tool]\\nllm_with_tools = llm.bind_tools(tools)\\n\\ndef chatbot(state: State):\\n    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\ntool_node = ToolNode(tools=[tool])\\ngraph_builder.add_node(\"tools\", tool_node)\\n\\ngraph_builder.add_conditional_edges(\\n    \"chatbot\",\\n    tools_condition,\\n)\\n# Any time a tool is called, we return to the chatbot to decide the next step\\ngraph_builder.add_edge(\"tools\", \"chatbot\")\\ngraph_builder.add_edge(START, \"chatbot\")\\ngraph = graph_builder.compile()\\n\\nCongratulations! You\\'ve created a conversational agent in LangGraph that can use a search engine to retrieve updated information when needed. Now it can handle a wider range of user queries.\\nTo inspect all the steps your agent just took, check out this LangSmith trace.\\nNext steps¶\\nThe chatbot cannot remember past interactions on its own, which limits its ability to have coherent, multi-turn conversations. In the next part, you will add memory to address this.\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                1. Build a basic chatbot\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                3. Add memory\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')],\n",
       " [Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/get-started/4-human-in-the-loop/', 'title': '4. Add human-in-the-loop', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4. Add human-in-the-loop\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\nLangGraph Platform docs have moved! Find the LangGraph Platform docs at the new LangChain Docs site.\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              4. Add human-in-the-loop\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Get started\\n          \\n\\n\\n\\n\\n\\n    Quickstarts\\n    \\n  \\n\\n\\n\\n\\n\\n            Quickstarts\\n          \\n\\n\\n\\n\\n    Start with a prebuilt agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Build a custom workflow\\n    \\n  \\n\\n\\n\\n\\n\\n            Build a custom workflow\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    1. Build a basic chatbot\\n    \\n  \\n\\n\\n\\n\\n\\n    2. Add tools\\n    \\n  \\n\\n\\n\\n\\n\\n    3. Add memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    4. Add human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n    4. Add human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      1. Add the human_assistance tool\\n    \\n\\n\\n\\n\\n\\n      2. Compile the graph\\n    \\n\\n\\n\\n\\n\\n      3. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      4. Prompt the chatbot\\n    \\n\\n\\n\\n\\n\\n      5. Resume execution\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    5. Customize state\\n    \\n  \\n\\n\\n\\n\\n\\n    6. Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Run a local server\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    General concepts\\n    \\n  \\n\\n\\n\\n\\n\\n            General concepts\\n          \\n\\n\\n\\n\\n    Workflows & agents\\n    \\n  \\n\\n\\n\\n\\n\\n    Agent architectures\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      1. Add the human_assistance tool\\n    \\n\\n\\n\\n\\n\\n      2. Compile the graph\\n    \\n\\n\\n\\n\\n\\n      3. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      4. Prompt the chatbot\\n    \\n\\n\\n\\n\\n\\n      5. Resume execution\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd human-in-the-loop controls¶\\nAgents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before running to ensure that everything is running as intended.\\nLangGraph\\'s persistence layer supports human-in-the-loop workflows, allowing execution to pause and resume based on user feedback. The primary interface to this functionality is the interrupt function. Calling interrupt inside a node will pause execution. Execution can be resumed, together with new input from a human, by passing in a Command.\\ninterrupt is ergonomically similar to Python\\'s built-in input(), with some caveats.\\n\\nNote\\nThis tutorial builds on Add memory.\\n\\n1. Add the human_assistance tool¶\\nStarting with the existing code from the Add memory to the chatbot tutorial, add the human_assistance tool to the chatbot. This tool uses interrupt to receive information from a human.\\nLet\\'s first select a chat model:\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n👉 Read the OpenAI integration docs\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n👉 Read the Anthropic integration docs\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n👉 Read the Azure integration docs\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n👉 Read the Google GenAI integration docs\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n👉 Read the AWS Bedrock integration docs\\n\\n\\n\\n\\nWe can now incorporate it into our StateGraph with an additional tool:\\nfrom typing import Annotated\\n\\nfrom langchain_tavily import TavilySearch\\nfrom langchain_core.tools import tool\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.checkpoint.memory import InMemorySaver\\nfrom langgraph.graph import StateGraph, START, END\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.prebuilt import ToolNode, tools_condition\\n\\nfrom langgraph.types import Command, interrupt\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\ngraph_builder = StateGraph(State)\\n\\n@tool\\ndef human_assistance(query: str) -> str:\\n    \"\"\"Request assistance from a human.\"\"\"\\n    human_response = interrupt({\"query\": query})\\n    return human_response[\"data\"]\\n\\ntool = TavilySearch(max_results=2)\\ntools = [tool, human_assistance]\\nllm_with_tools = llm.bind_tools(tools)\\n\\ndef chatbot(state: State):\\n    message = llm_with_tools.invoke(state[\"messages\"])\\n    # Because we will be interrupting during tool execution,\\n    # we disable parallel tool calling to avoid repeating any\\n    # tool invocations when we resume.\\n    assert len(message.tool_calls) <= 1\\n    return {\"messages\": [message]}\\n\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\ntool_node = ToolNode(tools=tools)\\ngraph_builder.add_node(\"tools\", tool_node)\\n\\ngraph_builder.add_conditional_edges(\\n    \"chatbot\",\\n    tools_condition,\\n)\\ngraph_builder.add_edge(\"tools\", \"chatbot\")\\ngraph_builder.add_edge(START, \"chatbot\")\\n\\n\\nTip\\nFor more information and examples of human-in-the-loop workflows, see Human-in-the-loop.\\n\\n2. Compile the graph¶\\nWe compile the graph with a checkpointer, as before:\\nmemory = InMemorySaver()\\n\\ngraph = graph_builder.compile(checkpointer=memory)\\n\\n3. Visualize the graph (optional)¶\\nVisualizing the graph, you get the same layout as before – just with the added tool!\\nfrom IPython.display import Image, display\\n\\ntry:\\n    display(Image(graph.get_graph().draw_mermaid_png()))\\nexcept Exception:\\n    # This requires some extra dependencies and is optional\\n    pass\\n\\n\\n4. Prompt the chatbot¶\\nNow, prompt the chatbot with a question that will engage the new human_assistance tool:\\nuser_input = \"I need some expert guidance for building an AI agent. Could you request assistance for me?\"\\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\\n\\nevents = graph.stream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n    config,\\n    stream_mode=\"values\",\\n)\\nfor event in events:\\n    if \"messages\" in event:\\n        event[\"messages\"][-1].pretty_print()\\n\\n================================ Human Message =================================\\n\\nI need some expert guidance for building an AI agent. Could you request assistance for me?\\n================================== Ai Message ==================================\\n\\n[{\\'text\\': \"Certainly! I\\'d be happy to request expert assistance for you regarding building an AI agent. To do this, I\\'ll use the human_assistance function to relay your request. Let me do that for you now.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01ABUqneqnuHNuo1vhfDFQCW\\', \\'input\\': {\\'query\\': \\'A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\nTool Calls:\\n  human_assistance (toolu_01ABUqneqnuHNuo1vhfDFQCW)\\n Call ID: toolu_01ABUqneqnuHNuo1vhfDFQCW\\n  Args:\\n    query: A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\n\\nThe chatbot generated a tool call, but then execution has been interrupted. If you inspect the graph state, you see that it stopped at the tools node:\\nsnapshot = graph.get_state(config)\\nsnapshot.next\\n\\n(\\'tools\\',)\\n\\n\\nInfo\\nTake a closer look at the human_assistance tool:\\n@tool\\ndef human_assistance(query: str) -> str:\\n    \"\"\"Request assistance from a human.\"\"\"\\n    human_response = interrupt({\"query\": query})\\n    return human_response[\"data\"]\\n\\nSimilar to Python\\'s built-in input() function, calling interrupt inside the tool will pause execution. Progress is persisted based on the checkpointer; so if it is persisting with Postgres, it can resume at any time as long as the database is alive. In this example, it is persisting with the in-memory checkpointer and can resume any time if the Python kernel is running.\\n\\n5. Resume execution¶\\nTo resume execution, pass a Command object containing data expected by the tool. The format of this data can be customized based on needs.\\nFor this example, use a dict with a key \"data\":\\nhuman_response = (\\n    \"We, the experts are here to help! We\\'d recommend you check out LangGraph to build your agent.\"\\n    \" It\\'s much more reliable and extensible than simple autonomous agents.\"\\n)\\n\\nhuman_command = Command(resume={\"data\": human_response})\\n\\nevents = graph.stream(human_command, config, stream_mode=\"values\")\\nfor event in events:\\n    if \"messages\" in event:\\n        event[\"messages\"][-1].pretty_print()\\n\\n================================== Ai Message ==================================\\n\\n[{\\'text\\': \"Certainly! I\\'d be happy to request expert assistance for you regarding building an AI agent. To do this, I\\'ll use the human_assistance function to relay your request. Let me do that for you now.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01ABUqneqnuHNuo1vhfDFQCW\\', \\'input\\': {\\'query\\': \\'A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\nTool Calls:\\n  human_assistance (toolu_01ABUqneqnuHNuo1vhfDFQCW)\\n Call ID: toolu_01ABUqneqnuHNuo1vhfDFQCW\\n  Args:\\n    query: A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\n================================= Tool Message =================================\\nName: human_assistance\\n\\nWe, the experts are here to help! We\\'d recommend you check out LangGraph to build your agent. It\\'s much more reliable and extensible than simple autonomous agents.\\n================================== Ai Message ==================================\\n\\nThank you for your patience. I\\'ve received some expert advice regarding your request for guidance on building an AI agent. Here\\'s what the experts have suggested:\\n\\nThe experts recommend that you look into LangGraph for building your AI agent. They mention that LangGraph is a more reliable and extensible option compared to simple autonomous agents.\\n\\nLangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\n\\n1. Reliability: The experts emphasize that LangGraph is more reliable than simpler autonomous agent approaches. This could mean it has better stability, error handling, or consistent performance.\\n\\n2. Extensibility: LangGraph is described as more extensible, which suggests that it probably offers a flexible architecture that allows you to easily add new features or modify existing ones as your agent\\'s requirements evolve.\\n\\n3. Advanced capabilities: Given that it\\'s recommended over \"simple autonomous agents,\" LangGraph likely provides more sophisticated tools and techniques for building complex AI agents.\\n...\\n2. Look for tutorials or guides specifically focused on building AI agents with LangGraph.\\n3. Check if there are any community forums or discussion groups where you can ask questions and get support from other developers using LangGraph.\\n\\nIf you\\'d like more specific information about LangGraph or have any questions about this recommendation, please feel free to ask, and I can request further assistance from the experts.\\nOutput is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\\n\\nThe input has been received and processed as a tool message. Review this call\\'s LangSmith trace to see the exact work that was done in the above call. Notice that the state is loaded in the first step so that our chatbot can continue where it left off.\\nCongratulations! You\\'ve used an interrupt to add human-in-the-loop execution to your chatbot, allowing for human oversight and intervention when needed. This opens up the potential UIs you can create with your AI systems. Since you have already added a checkpointer, as long as the underlying persistence layer is running, the graph can be paused indefinitely and resumed at any time as if nothing had happened.\\nCheck out the code snippet below to review the graph from this tutorial:\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n👉 Read the OpenAI integration docs\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n👉 Read the Anthropic integration docs\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n👉 Read the Azure integration docs\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n👉 Read the Google GenAI integration docs\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n👉 Read the AWS Bedrock integration docs\\n\\n\\n\\nAPI Reference: TavilySearch | tool | InMemorySaver | StateGraph | START | END | add_messages | ToolNode | tools_condition | Command | interrupt\\nfrom typing import Annotated\\n\\nfrom langchain_tavily import TavilySearch\\nfrom langchain_core.tools import tool\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.checkpoint.memory import InMemorySaver\\nfrom langgraph.graph import StateGraph, START, END\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.prebuilt import ToolNode, tools_condition\\nfrom langgraph.types import Command, interrupt\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\ngraph_builder = StateGraph(State)\\n\\n@tool\\ndef human_assistance(query: str) -> str:\\n    \"\"\"Request assistance from a human.\"\"\"\\n    human_response = interrupt({\"query\": query})\\n    return human_response[\"data\"]\\n\\ntool = TavilySearch(max_results=2)\\ntools = [tool, human_assistance]\\nllm_with_tools = llm.bind_tools(tools)\\n\\ndef chatbot(state: State):\\n    message = llm_with_tools.invoke(state[\"messages\"])\\n    assert(len(message.tool_calls) <= 1)\\n    return {\"messages\": [message]}\\n\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\ntool_node = ToolNode(tools=tools)\\ngraph_builder.add_node(\"tools\", tool_node)\\n\\ngraph_builder.add_conditional_edges(\\n    \"chatbot\",\\n    tools_condition,\\n)\\ngraph_builder.add_edge(\"tools\", \"chatbot\")\\ngraph_builder.add_edge(START, \"chatbot\")\\n\\nmemory = InMemorySaver()\\ngraph = graph_builder.compile(checkpointer=memory)\\n\\nNext steps¶\\nSo far, the tutorial examples have relied on a simple state with one entry: a list of messages. You can go far with this simple state, but if you want to define complex behavior without relying on the message list, you can add additional fields to the state.\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                3. Add memory\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                5. Customize state\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141b85d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "779a7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# Setup Gemini embeddings\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key= gamini_key # Or set GOOGLE_API_KEY environment variable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "768b16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_list=[item for sublist in docs for item in sublist]\n",
    "text_spliter=RecursiveCharacterTextSplitter(chunk_size=100,chunk_overlap=50)\n",
    "doc_split=text_spliter.split_documents(docs_list)\n",
    "\n",
    "vectorstore=FAISS.from_documents(\n",
    "    documents=doc_split,\n",
    "    embedding=gemini_embeddings\n",
    ")\n",
    "\n",
    "retriver=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df4294f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='07935e8c-c8e9-4f99-8a73-97e9daef78c2', metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/get-started/2-add-tools/', 'title': '2. Add tools', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='LangGraph works in conjunction with LangSmith, another tool by LangChain, to provide an'),\n",
       " Document(id='c8383a74-5c58-4a26-8844-bbedaef62c97', metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/get-started/2-add-tools/', 'title': '2. Add tools', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to'),\n",
       " Document(id='dde2c1e8-2cae-4cc9-bac0-b07cd15adefa', metadata={'source': 'https://langchain-ai.github.io/langgraph/concepts/why-langgraph/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"To get acquainted with LangGraph's key concepts and features, complete the following LangGraph\"),\n",
       " Document(id='640926df-fe08-4c9d-b23f-13f3765b5acc', metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/get-started/2-add-tools/', 'title': '2. Add tools', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='4. Use Cases:\\n   LangGraph can be used for various applications, including:')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver.invoke(\"what is langgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e369a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever=create_retriever_tool(\n",
    "    retriver,\n",
    "    \"vector\",\n",
    "    \"search and run information about langgrah\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1854dc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='vector', description='search and run information about langgrah', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000028F3DD34720>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000028F77E45520>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000028F3DD34B80>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000028F77E45520>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b86e141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[retriever]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf4c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph , START ,END\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "\n",
    "graph=StateGraph(AgentState)\n",
    "graph.add_node('agent',agent)\n",
    "retriever=ToolNode([retriever_tool])\n",
    "graph.add\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraphx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
